{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# **Mildew Detector for Cherry Trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "* Fetch data from Kaggle and prepare it for further ML processing.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* Kaggle.json file -authentication token\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Generate Dataset: inputs/datasets/cherry_leaves\n",
    "\n",
    "## Additional Comments\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqP-UeN-z3i2"
   },
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wZfF_j-Bz3i4",
    "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
   },
   "outputs": [],
   "source": [
    "# import numpy\n",
    "import os\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/P5-Mildew-Detection-in-Cherry-Leaves/jupyter_notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TwHsQRWjz3i9",
    "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/workspace/P5-Mildew-Detection-in-Cherry-Leaves')\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_xPk_Ijz3i-"
   },
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vz3S-_kjz3jA",
    "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/P5-Mildew-Detection-in-Cherry-Leaves'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.19.2 (from -r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 1))\n",
      "  Downloading numpy-1.19.2-cp38-cp38-manylinux2010_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting pandas==1.1.2 (from -r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 2))\n",
      "  Downloading pandas-1.1.2-cp38-cp38-manylinux1_x86_64.whl.metadata (4.7 kB)\n",
      "Collecting matplotlib==3.3.1 (from -r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 3))\n",
      "  Downloading matplotlib-3.3.1-cp38-cp38-manylinux1_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting seaborn==0.11.0 (from -r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 4))\n",
      "  Downloading seaborn-0.11.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting plotly==4.12.0 (from -r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 5))\n",
      "  Downloading plotly-4.12.0-py2.py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting streamlit==0.85.0 (from -r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7))\n",
      "  Downloading streamlit-0.85.0-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting scikit-learn==0.24.2 (from -r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 9))\n",
      "  Downloading scikit_learn-0.24.2-cp38-cp38-manylinux2010_x86_64.whl.metadata (9.8 kB)\n",
      "Collecting tensorflow-cpu==2.6.0 (from -r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading tensorflow_cpu-2.6.0-cp38-cp38-manylinux2010_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting keras==2.6.0 (from -r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 11))\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting protobuf==3.20 (from -r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 12))\n",
      "  Downloading protobuf-3.20.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (698 bytes)\n",
      "Collecting altair<5 (from -r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 13))\n",
      "  Downloading altair-4.2.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from pandas==1.1.2->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from pandas==1.1.2->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 2)) (2024.2)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from matplotlib==3.3.1->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 3)) (2024.8.30)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.3.1->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 3))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib==3.3.1->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 3))\n",
      "  Downloading kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /workspace/.pip-modules/lib/python3.8/site-packages (from matplotlib==3.3.1->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 3)) (9.5.0)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 (from matplotlib==3.3.1->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 3))\n",
      "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting scipy>=1.0 (from seaborn==0.11.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 4))\n",
      "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "Collecting retrying>=1.3.3 (from plotly==4.12.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 5))\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: six in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from plotly==4.12.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 5)) (1.16.0)\n",
      "Collecting astor (from streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7))\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: attrs in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (24.2.0)\n",
      "Collecting base58 (from streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7))\n",
      "  Downloading base58-2.1.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: blinker in /workspace/.pip-modules/lib/python3.8/site-packages (from streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (1.8.2)\n",
      "Requirement already satisfied: cachetools>=4.0 in /workspace/.pip-modules/lib/python3.8/site-packages (from streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (5.5.1)\n",
      "Collecting click<8.0,>=7.0 (from streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7))\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: packaging in /workspace/.pip-modules/lib/python3.8/site-packages (from streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (23.2)\n",
      "Requirement already satisfied: pyarrow in /workspace/.pip-modules/lib/python3.8/site-packages (from streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (17.0.0)\n",
      "Requirement already satisfied: pydeck>=0.1.dev5 in /workspace/.pip-modules/lib/python3.8/site-packages (from streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (0.9.1)\n",
      "Requirement already satisfied: requests in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (2.32.3)\n",
      "Requirement already satisfied: toml in /workspace/.pip-modules/lib/python3.8/site-packages (from streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (0.10.2)\n",
      "Requirement already satisfied: tornado>=5.0 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (6.4.2)\n",
      "Requirement already satisfied: tzlocal in /workspace/.pip-modules/lib/python3.8/site-packages (from streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (4.3.1)\n",
      "Requirement already satisfied: validators in /workspace/.pip-modules/lib/python3.8/site-packages (from streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (0.34.0)\n",
      "Requirement already satisfied: gitpython in /workspace/.pip-modules/lib/python3.8/site-packages (from streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (3.1.44)\n",
      "Requirement already satisfied: watchdog in /workspace/.pip-modules/lib/python3.8/site-packages (from streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (4.0.2)\n",
      "Collecting joblib>=0.11 (from scikit-learn==0.24.2->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 9))\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn==0.24.2->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 9))\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting absl-py~=0.10 (from tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting astunparse~=1.6.3 (from tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting clang~=5.0 (from tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting flatbuffers~=1.12.0 (from tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl.metadata (872 bytes)\n",
      "Collecting google-pasta~=0.2 (from tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py~=3.1.0 (from tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading h5py-3.1.0-cp38-cp38-manylinux1_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting keras-preprocessing~=1.1.2 (from tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opt-einsum~=3.3.0 (from tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting six (from plotly==4.12.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 5))\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting termcolor~=1.1.0 (from tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting typing-extensions~=3.7.4 (from tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10)) (0.45.1)\n",
      "Collecting wrapt~=1.12.1 (from tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gast==0.4.0 (from tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting tensorboard~=2.6 (from tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading tensorboard-2.14.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator~=2.6 (from tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting grpcio<2.0,>=1.37.0 (from tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading grpcio-1.70.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting entrypoints (from altair<5->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 13))\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: jinja2 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from altair<5->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 13)) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from altair<5->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 13)) (4.23.0)\n",
      "Collecting toolz (from altair<5->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 13))\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from jsonschema>=3.0->altair<5->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 13)) (6.4.5)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from jsonschema>=3.0->altair<5->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 13)) (2023.12.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from jsonschema>=3.0->altair<5->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 13)) (1.3.10)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from jsonschema>=3.0->altair<5->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 13)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from jsonschema>=3.0->altair<5->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 13)) (0.20.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from jinja2->altair<5->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 13)) (2.1.5)\n",
      "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting scipy>=1.0 (from seaborn==0.11.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 4))\n",
      "  Downloading scipy-1.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "  Downloading scipy-1.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard~=2.6->tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard~=2.6->tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.6->tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10)) (75.3.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.6->tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.6->tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from requests->streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from requests->streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from requests->streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (2.2.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /workspace/.pip-modules/lib/python3.8/site-packages (from gitpython->streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (4.0.12)\n",
      "Requirement already satisfied: pytz-deprecation-shim in /workspace/.pip-modules/lib/python3.8/site-packages (from tzlocal->streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (0.1.0.post0)\n",
      "Requirement already satisfied: backports.zoneinfo in /workspace/.pip-modules/lib/python3.8/site-packages (from tzlocal->streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (0.2.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /workspace/.pip-modules/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython->streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (5.0.2)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard~=2.6->tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema>=3.0->altair<5->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 13)) (3.20.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /workspace/.pip-modules/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10)) (6.11.0)\n",
      "Requirement already satisfied: tzdata in /workspace/.pip-modules/lib/python3.8/site-packages (from pytz-deprecation-shim->tzlocal->streamlit==0.85.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 7)) (2025.1)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard~=2.6->tensorflow-cpu==2.6.0->-r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt (line 10))\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Downloading numpy-1.19.2-cp38-cp38-manylinux2010_x86_64.whl (14.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m144.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-1.1.2-cp38-cp38-manylinux1_x86_64.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m270.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.3.1-cp38-cp38-manylinux1_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading seaborn-0.11.0-py3-none-any.whl (283 kB)\n",
      "Downloading plotly-4.12.0-py2.py3-none-any.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading streamlit-0.85.0-py2.py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-0.24.2-cp38-cp38-manylinux2010_x86_64.whl (24.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m201.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_cpu-2.6.0-cp38-cp38-manylinux2010_x86_64.whl (172.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.4/172.4 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-3.20.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Downloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.70.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m236.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.1.0-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m151.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Downloading kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Downloading scipy-1.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m154.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading tensorboard-2.14.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m205.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
      "Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m273.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: clang, termcolor, wrapt\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30680 sha256=1cd0477c58a95e933413c17a9b651fa14092d5e5965334bbebd070780650f301\n",
      "  Stored in directory: /home/gitpod/.cache/pip/wheels/f1/60/77/22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4831 sha256=ae7017f6153a6f24f91960609e6048ffbf6f7eb2bd0d155023f856e3a0902ca1\n",
      "  Stored in directory: /home/gitpod/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-linux_x86_64.whl size=75903 sha256=f700f8cfce70a5792c05f0c6f657bc38a1a8dc7f1a22c667591db47bef58ec4f\n",
      "  Stored in directory: /home/gitpod/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "Successfully built clang termcolor wrapt\n",
      "Installing collected packages: wrapt, typing-extensions, termcolor, keras, flatbuffers, clang, werkzeug, toolz, threadpoolctl, tensorflow-estimator, tensorboard-data-server, six, pyparsing, pyasn1, protobuf, oauthlib, numpy, kiwisolver, joblib, grpcio, gast, entrypoints, cycler, click, base58, astor, scipy, rsa, retrying, requests-oauthlib, pyasn1-modules, opt-einsum, markdown, keras-preprocessing, h5py, google-pasta, astunparse, absl-py, scikit-learn, plotly, pandas, matplotlib, google-auth, seaborn, google-auth-oauthlib, altair, tensorboard, streamlit, tensorflow-cpu\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.6\n",
      "    Uninstalling protobuf-4.25.6:\n",
      "      Successfully uninstalled protobuf-4.25.6\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.8\n",
      "    Uninstalling click-8.1.8:\n",
      "      Successfully uninstalled click-8.1.8\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.0.3\n",
      "    Uninstalling pandas-2.0.3:\n",
      "      Successfully uninstalled pandas-2.0.3\n",
      "  Attempting uninstall: altair\n",
      "    Found existing installation: altair 5.4.1\n",
      "    Uninstalling altair-5.4.1:\n",
      "      Successfully uninstalled altair-5.4.1\n",
      "  Attempting uninstall: streamlit\n",
      "    Found existing installation: streamlit 1.25.0\n",
      "    Uninstalling streamlit-1.25.0:\n",
      "      Successfully uninstalled streamlit-1.25.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anyio 4.5.2 requires typing-extensions>=4.1; python_version < \"3.11\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
      "async-lru 2.0.4 requires typing-extensions>=4.0.0; python_version < \"3.11\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
      "rich 13.9.4 requires typing-extensions<5.0,>=4.0.0; python_version < \"3.11\", but you have typing-extensions 3.7.4.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-0.15.0 altair-4.2.2 astor-0.8.1 astunparse-1.6.3 base58-2.1.1 clang-5.0 click-7.1.2 cycler-0.12.1 entrypoints-0.4 flatbuffers-1.12 gast-0.4.0 google-auth-2.38.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.70.0 h5py-3.1.0 joblib-1.4.2 keras-2.6.0 keras-preprocessing-1.1.2 kiwisolver-1.4.7 markdown-3.7 matplotlib-3.3.1 numpy-1.19.2 oauthlib-3.2.2 opt-einsum-3.3.0 pandas-1.1.2 plotly-4.12.0 protobuf-3.20.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pyparsing-3.1.4 requests-oauthlib-2.0.0 retrying-1.3.4 rsa-4.9 scikit-learn-0.24.2 scipy-1.9.3 seaborn-0.11.0 six-1.15.0 streamlit-0.85.0 tensorboard-2.14.0 tensorboard-data-server-0.7.2 tensorflow-cpu-2.6.0 tensorflow-estimator-2.15.0 termcolor-1.1.0 threadpoolctl-3.5.0 toolz-1.0.0 typing-extensions-3.7.4.3 werkzeug-3.0.6 wrapt-1.12.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r /workspace/P5-Mildew-Detection-in-Cherry-Leaves/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "# Install Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 1 content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Kaggle package\n",
    "!pip install kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the Kaggle configuration directory to current working directory and permission of Kaggle authentication json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
    "! chmod 600 kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Kaggle Dataset and download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KaggleDatasetPath = \"codeinstitute/cherry-leaves\"\n",
    "DestinationFolder = \"inputs/cherry_leaves\"\n",
    "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip the downloaded file, and delete the zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(DestinationFolder + '/cherry-leaves.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(DestinationFolder)\n",
    "\n",
    "os.remove(DestinationFolder + '/cherry-leaves.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFQo3ycuO-v6"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check and Remove non-image files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_non_image_file(my_data_dir):\n",
    "    image_extension = ('.png', '.jpg', '.jpeg')\n",
    "    folders = os.listdir(my_data_dir)\n",
    "    for folder in folders:\n",
    "        files = os.listdir(my_data_dir + '/' + folder)\n",
    "        # print(files)\n",
    "        i = []\n",
    "        j = []\n",
    "        for given_file in files:\n",
    "            if not given_file.lower().endswith(image_extension):\n",
    "                file_location = my_data_dir + '/' + folder + '/' + given_file\n",
    "                os.remove(file_location)  # remove non image file\n",
    "                i.append(1)\n",
    "            else:\n",
    "                j.append(1)\n",
    "                pass\n",
    "        print(f\"Folder: {folder} - has image file\", len(j))\n",
    "        print(f\"Folder: {folder} - has non-image file\", len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_non_image_file(my_data_dir='inputs/cherry_leaves/cherry-leaves')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for corrupted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the dataset directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_dir = 'inputs/cherry_leaves/cherry-leaves'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize list to track corrupted images and iterate through the dataset to check for corrupted images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_files = []\n",
    "\n",
    "# Iterate through the dataset to check for corrupted images\n",
    "print(\"Checking for corrupted images...\")\n",
    "for root, _, files in os.walk(my_data_dir):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        try:\n",
    "            # Try opening the image to detect corruption\n",
    "            with Image.open(file_path) as img:\n",
    "                img.verify()\n",
    "        except (FileNotFoundError, OSError):\n",
    "            corrupted_files.append(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if corrupted_files:\n",
    "    print(\"Corrupted files detected:\")\n",
    "    for file in corrupted_files:\n",
    "        print(file)\n",
    "else:\n",
    "    print(\"No corrupted files found.\")\n",
    "\n",
    "# Save results to a text file\n",
    "with open(\"corrupted_files_log.txt\", \"w\") as log_file:\n",
    "    if corrupted_files:\n",
    "        log_file.write(\"Corrupted files:\\n\")\n",
    "        log_file.writelines([f\"{file}\\n\" for file in corrupted_files])\n",
    "\n",
    "print(\"Check completed. Results logged to corrupted_files_log.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):\n",
    "    \"\"\"\n",
    "    Split the dataset of images into train, validation, and test sets.\n",
    "\n",
    "    Args:\n",
    "        my_data_dir (str): Path to the dataset directory containing class folders.\n",
    "        train_set_ratio (float): Proportion of data to be used for training.\n",
    "        validation_set_ratio (float): Proportion of data to be used for validation.\n",
    "        test_set_ratio (float): Proportion of data to be used for testing.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Check if ratios sum to 1.0\n",
    "    if not abs(train_set_ratio + validation_set_ratio + test_set_ratio - 1.0) < 1e-6:\n",
    "        raise ValueError(\"train_set_ratio, validation_set_ratio, and test_set_ratio should sum to 1.0.\")\n",
    "\n",
    "    # Get class labels (folder names)\n",
    "    labels = [label for label in os.listdir(my_data_dir) if os.path.isdir(os.path.join(my_data_dir, label))]\n",
    "\n",
    "    # Create train, validation, test directories\n",
    "    for folder in ['train', 'validation', 'test']:\n",
    "        for label in labels:\n",
    "            os.makedirs(os.path.join(my_data_dir, folder, label), exist_ok=True)\n",
    "\n",
    "    for label in labels:\n",
    "        class_dir = os.path.join(my_data_dir, label)\n",
    "        files = [file for file in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, file))]\n",
    "        random.shuffle(files)\n",
    "\n",
    "        # Calculate split indices\n",
    "        train_count = int(len(files) * train_set_ratio)\n",
    "        val_count = int(len(files) * validation_set_ratio)\n",
    "        \n",
    "        train_files = files[:train_count]\n",
    "        val_files = files[train_count:train_count + val_count]\n",
    "        test_files = files[train_count + val_count:]\n",
    "\n",
    "        # Move files to corresponding folders\n",
    "        for file in train_files:\n",
    "            shutil.move(os.path.join(class_dir, file), os.path.join(my_data_dir, 'train', label, file))\n",
    "\n",
    "        for file in val_files:\n",
    "            shutil.move(os.path.join(class_dir, file), os.path.join(my_data_dir, 'validation', label, file))\n",
    "\n",
    "        for file in test_files:\n",
    "            shutil.move(os.path.join(class_dir, file), os.path.join(my_data_dir, 'test', label, file))\n",
    "\n",
    "        # Remove the original class folder if empty\n",
    "        if not os.listdir(class_dir):\n",
    "            os.rmdir(class_dir)\n",
    "\n",
    "    print(\"Data successfully split into train, validation, and test sets.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train_validation_test_images(my_data_dir = f\"inputs/cherry_leaves/cherry-leaves\",\n",
    "                        train_set_ratio = 0.7,\n",
    "                        validation_set_ratio=0.1,\n",
    "                        test_set_ratio=0.2\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify class balance in training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path to the training set\n",
    "train_dir = \"inputs/cherry_leaves/cherry-leaves/train\"\n",
    "\n",
    "# Count and plot for training set only\n",
    "train_classes = os.listdir(train_dir)\n",
    "train_class_counts = {cls: len(os.listdir(os.path.join(train_dir, cls))) for cls in train_classes}\n",
    "\n",
    "print(\"Training Set Class Distribution:\", train_class_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bar chart for class distribution\n",
    "plt.bar(train_class_counts.keys(), train_class_counts.values(), color=['green', 'red'])\n",
    "plt.title('Training Set Class Distribution')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the validation set - Just to be aware of any natural inconsistencies or huge imbalances. This check will be used when the data set increases with more species and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the validation set\n",
    "validation_dir = \"inputs/cherry_leaves/cherry-leaves/validation\"\n",
    "\n",
    "# Count and plot for validation set\n",
    "validation_classes = os.listdir(validation_dir)\n",
    "validation_class_counts = {cls: len(os.listdir(os.path.join(validation_dir, cls))) for cls in validation_classes}\n",
    "\n",
    "print(\"Validation Set Class Distribution:\", validation_class_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltNetd085qHf"
   },
   "source": [
    "# Push files to Repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
